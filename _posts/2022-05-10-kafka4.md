---
layout: post
title: Kafka - 4!
subtitle: kafka 책 읽기
categories: kafka
tags: [kafka]
---

## 카프카 커넥트

 - 카프카 오픈소스에 포함된 툴 중 하나
 - 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션
   - 파이프라인 생성 시 자주 반복되는 값들 (토픽 이름, 파일 이름, 테이블 이름 등)을 파라미터로 받는 커넥터를 코드로 작성시 이후에 파이프라인을 실행할 때 코드 작성할 필요 없음

![image](https://user-images.githubusercontent.com/62547169/167628346-c41a69e1-3e48-4ac8-a4de-fe858f1f9fef.png)


참고: https://bagbokman.tistory.com/8


> 카프카 커넥트 : Connector를 동작하게 하는 서버
> 
> 카프카 커넥터 : jar파일




### 소스, 싱크 커넥터

- `소스 커넥터` : 커넥트에서 프로듀서 역할을 하는 커넥터
- `싱크 커넥터` : 커넥트에서 컨슈머 역할을 하는 커넥터
- 파일을 주고 받는 파일 소스 커넥터 예시
  - 파일 소스 커넥터는 파일의 데이터를 카프카 토픽으로 전송하는 프로듀서 역할
  - 파일 싱크 커넥터는 토픽의 데이터를 파일로 저장하는 컨슈머 역할

### 커넥터 종류

- 카프카 2.6에 포함된 커넥트는 미러메이커2, 파일 싱크 커넥터, 파일 소스 커넥터를 기본 플로그인으로 제공
- 오픈소스 : JDBC, 엘라스틱서치, HDFS 커넥터 등 100가지가 넘는 오픈소스 커넥터가 공개 되어있음

![image](https://user-images.githubusercontent.com/62547169/167629578-ae27da83-cfa3-4b50-a2f9-5eb9504956bd.png)


### 커넥터 태스크

- 커넥터는 태스크들을 관리
- 사용자가 커넥트에 커넥터 생성 명령을 내리면 커넥트는 내부에 커넥터와 태스크를 생성
- 태스크는 커넥터에 종속되는 개념으로 실질적인 데이터 처리를 수행
- 데이터 처리를 정상적으로 하는지 확인하기 위해서 각 태스크의 상태를 확인해야함


![image](https://user-images.githubusercontent.com/62547169/167631219-3363f628-6e44-4256-b77b-70e0e13ce14c.png)


### 컨버터, 트랜스폼

- 사용자가 파이프라인을 생성할 때 컨버터와 트랜스폼 기능을 옵션으로 추가 가능
- `컨버터` : 데이터를 처리 하기 전에 스키마를 변경하도록 도외줌 : JsonConverter, StringConverter, ByteArrayConverter, 커스텀
- `트랜스폼` : 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용
  - Json 데이터를 커넥터에 사용할 때, 트랜스폼을 사용하면 특정 키를 삭제하거나 추가할 수 있음 : 기본 제공 트랜스폼 Cast, Drop 등 존재


## 커넥트 실행 방법

- 카프카 커넥트를 실행하는 방법은 `단일 모드 커넥트`와 `분산 모드 커넥트`로 2가지가 존재

### 단일 모드 커넥트

- 1개의 프로세스만으로 실행
- 고가용성이 구성되지 않아 단일 장애점이 될 수 있음
- 중요도가 낮은 파이프라인을 운영할 때 사용

단일 장애점 : https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%9D%BC_%EC%9E%A5%EC%95%A0%EC%A0%90

![image](https://user-images.githubusercontent.com/62547169/167633254-9f7c0c1b-44b9-45fb-a4ce-793910496311.png)



### 분산 모드 커넥트

- 2대 이상의 서버에서 클러스터 형태로 운영
  - 중단이 되더라도 남은 1개의 커넥트가 파이프라인을 지속적으로 처리 가능
- 데이터 처리량의 변화에서도 유연하게 대응 가능 -> 스케일 아웃하여 처리량 증가 가능

![image](https://user-images.githubusercontent.com/62547169/167633534-29ad531a-5946-47be-a129-a483aa66c079.png)



### REST API

- REST API를 통해서 현재 실행 중인 커넥트의 커넥터 플러그인 종류, 태스크 상태, 커넥터 상태 등 조회 가능

|요청 메서드|경로|설명|
|------|---|---|
|GET|/|실행 중인 커넥트 정보 확인|
|GET|/connectors|실행 중인 커넥트 이름 확인|
|POST|/connectors|새로운 커넥터 생성 요청|
|GET|/connectors/(커넥터 이름)|실행 중인 커넥터 정보 확인|
|GET|/connectors/(커넥터 이름)/config|실행중인 커넥터의 설정값 확인|
|PUT|/connectors/(커넥터 이름)/config|실행중인 커넥터의 설정값 변경 요청|
|GET|/connectors/(커넥터 이름)/status|실행중인 커넥터 상태 확인|
|POST|/connectors/(커넥터 이름)/restart|실행 중인 커넥터 재시작 요청|
|PUT|/connectors/(커넥터 이름)/pause|커넥터 일시 중지 요청|
|PUT|/connectors/(커넥터 이름)/resume|일시 중지된 커넥터 실행 요청|
|DELETE|/connectors/(커넥터 이름)/|실행 중인 커넥터 종료|
|GET|/connectors/(커넥터 이름)/tasks|실행 중인 커넥터의 태스크 정보 확인|
|GET|/connectors/(커넥터 이름)/tasks/(태스크 아이디)/status|실행 중인 커넥터의 태스크 상태 확인|
|POST|/connectors/(커넥터 이름)/tasks/(태스크 아이디)/restart|실행 중인 커넥터의 태스크 재시작 요청|
|GET|/connectors/(커넥터 이름)/topics|커넥터별 연동된 토픽 정보 확인|
|GET|/connector-plugins/|커넥트에 존재하는 커넥터 플러그인 확인|
|PUT|/connector-plugins/(커넥터 플러그인 이름)/config/validate|커넥터 생성 시 설정값 유효 여부 확인|


### 단일 모드 커넥트 설정

- 단일 모드 커넥트는 `커넥트 설정파일과 함께 커넥터 설정파일`도 정의하여 실행해야 함

connect-standalone.properties

```properties

bootstrap.servers=IP_ADDRESS:9092                                # 카프카와 연동할 카프카 클러스터의 주소
key.converter=org.apache.kafka.connect.json.JsonConverter        # 데이터를 카프카에 저장할 때, 가져올 때 변환하는데 사용 String, ByteArray Converter 기본 제공
value.converter=org.apache.kafka.connect.json.JsonConverter      
key.converter.schemas.enables=false
value.converter.schemas.enables=false

offset.storage.file.filename=/tmp/connect.offsets                # 단일 모드 커넥트는 로컬 파일에 오프셋 정보를 저장
                                                                 # 오프셋 정보는 소스, 싱크 커넥터가 데이터 처리 시점을 저장하기 위해 사용

offset.flush.interval.ms=10000                                   # 태스크가 처리 완료한 오프셋을 커밋하는 주기 설정
plugin.path=                                                     # 플러그인 형태로 추가할 커넥터의 디렉토리 주소 - 디렉토리 (,)로 구분 가능

```

file-source.properties

```properties

name=local-file-source              # 커넥터의 이름 지정
connector.class=FileStreamSource    # 사용할 커넥터의 클래스 이름 지정
tasks.max=1                         # 커넥터로 실행할 태스크 개수를 지정
file=/tmp/test.txt                  # 읽을 파일의 위치를 지정
topic=connect-text                  # 읽은 파일의 데이터를 저장할 토픽의 이름 지정

```


file-sink.properties

```properties
name=local-file-sink
connector.class=FileStreamSink
tasks.max=1
file=test.sink.txt
topics=connect-test
```




```bash
$ bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties
```


- test.txt에 내용 입력

![image](https://user-images.githubusercontent.com/62547169/167542479-74b0a302-3b90-4e01-9162-3ea7fda0bbfe.png)

- ./kafka-console-consumer.sh 에서 

![image](https://user-images.githubusercontent.com/62547169/167542631-c344c999-9391-4d7a-9def-a3781398d3f4.png)

- test.sink.txt 내용 출력

![image](https://user-images.githubusercontent.com/62547169/167544490-b3d78a0d-b80c-4c1b-8648-d1e49b4e122e.png)


### 분산 모드 커넥트 설정

connect-distributed.properties

```properties

bootstrap.servers=IP_ADDRESS:9092                               

group.id=cluster.name

key.converter=org.apache.kafka.connect.json.JsonConverter       
value.converter=org.apache.kafka.connect.json.JsonConverter      
key.converter.schemas.enables=false
value.converter.schemas.enables=false

offset.storage.topic=connect-offsets
offset.storage.replication.factor=1

offset.storage.topic=connect-configs
offset.storage.replication.factor=1

offset.storage.topic=connect-status
offset.storage.replication.factor=1

offset.flush.interval.ms=10000                                  
plugin.path=                                                   

```

```bash
$ bin/connect-distributed.sh config/connect-distributed.properties
```


## 소스 커넥터

- 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할
- 직접 구현한 소스 커넥터를 빌드 해서 jar파일로 만들어 플러그인으로 사용 가능

```gradle
dependencies{
  compile `org.apache.kafka:connect-api:2.5.0`
}
```

- 소스 커넥터를 만들 때 필요한 클래스

1. SourceConnector
  - 태스크를 실행하기 전에 커넥터 설정파일을 초기화 및 어떤 태스크 클래스를 사용할 것인지 정의
2. SourceTask
  - 실제로 데이터를 다루는 클래스로 소스 애플리케이션, 소스 파일로부터 데이터를 가져와 토픽으로 데이터를 보내는 역할 수행
  - 자체적으로 사용하는 오프셋을 사용 - 소스 애플리케이션, 소스 파일을 어디까지 읽었는지 저장하는 역할 (중복 방지)

SourceConnector

```java
public class TestSourceConnector extends SourceConnector {           // source 커넥터 구현

    @Override
    public String version() {}                                       
    // 커넥터의 버전을 리턴, 커넥트에 포함된 커넥터 플러그인 조회시 이 버전 노출

    @Override
    public void start(Map<String, String> props) {}                  
    // 사용자가 json, config로 작성한 설정값을 초기화 
    // 만약 올바른 값이 아닐 때 ConnectException()을 호출하여 커넥터를 종료 가능
    // JDBC의 URL

    @Override
    public Class<? extends Task> taskClass() {}
    // 커넥터가 사용할 태스크 클래스 지정

    @Override
    public List<Map<String, String>> taskConfigs(int maxTasks) {}
    // 태스크 수가 2개 이상인 경우 태스크 마다 각기 다른 옵션 설정

    @Override
    public ConfigDef config() {}
    // 커넥터가 사용할 설정값에 대한 정보 받기 ( 이름, 기본값, 중요도, 설명 정의 가능 )

    @Override
    public void stop() {}
    // 커넥트가 종료될 때 로직 작성
}
```


SourceTask

```java
public class TestSourceTask extends SourceTask {


    @Override
    public String version() {}
    // 버전 명시
    
    @Override
    public void start(Map<String, String> props) {}
    // 태스크가 시작할 때 필요한 로직 작성
    // 데이터 처리에 필요한 모든 리소스를 여기서 초기화하는 것이 좋음
    // JDBC 소스 커넥터를 구현한다면 JDBC 커넥션을 여기서 맺는다

    @Override
    public List<SourceRecord> poll() {}
    // 소스 애플리케이션 또는 소스 파일로부터 데이터를 읽어오는 로직 작성
    // 데이터를 읽어오면 토픽으로 보낼 데이터를 SourceRecord로 정의
    // SourceRecord클래스는 토픽으로 데이터를 정의하기 위해 사용

    @Override
    public void stop() {}
}
```

## 싱크 커넥터

- 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할

- 소스 커넥터를 만들 때 필요한 클래스
1. SinkConnector
  - 태스크를 실행하기 전에 커넥터 설정파일을 초기화 및 어떤 태스크 클래스를 사용할 것인지 정의

2. SinkTask
  - 실제 데이터 처리, 컨슈머 역할을 하고 데이터를 저장하는 코드를 가지게 


SinkConnector

```java
public class TestSinkConnector extends SinkConnector {  

    @Override
    public String version() {}                                       
    // 커넥터의 버전을 리턴, 커넥트에 포함된 커넥터 플러그인 조회시 이 버전 노출

    @Override
    public void start(Map<String, String> props) {}                  
    // 사용자가 json, config로 작성한 설정값을 초기화 
    // 만약 올바른 값이 아닐 때 ConnectException()을 호출하여 커넥터를 종료 가능
    // JDBC의 URL

    @Override
    public Class<? extends Task> taskClass() {}
    // 커넥터가 사용할 태스크 클래스 지정

    @Override
    public List<Map<String, String>> taskConfigs(int maxTasks) {}
    // 태스크 수가 2개 이상인 경우 태스크 마다 각기 다른 옵션 설정

    @Override
    public ConfigDef config() {}
    // 커넥터가 사용할 설정값에 대한 정보 받기 ( 이름, 기본값, 중요도, 설명 정의 가능 )

    @Override
    public void stop() {}
    // 커넥트가 종료될 때 로직 작성
}
```


SinkTask

```java
public class TestSourceTask extends SourceTask {


    @Override
    public String version() {}
    
    @Override
    public void start(Map<String, String> props) {}

    @Override
    public void put(Collection<SinkRecord> records) {}
    // 싱크 애플리케이션 또는 싱크 파일에 저장할 데이터를 토픽에서 주기적으로 가져오는 메서드
    // 토픽의 데이터들은 여러개의 SinkRecord를 묶어 파라미터로 사용할 수 있음
    // SinkRecord는 토픽의 한 개 레코드 이며 토픽, 파티션, 타임스탬프 등의 정보를 담고 있음
    
    @Override
    public void flush(Map<TopicPartition, OffsetAndMetadata> offsets) {}
    // put 메서드를 통해서 가져온 데이터를 일정 주기로 싱크 애플리케이션 또는 싱크 파일에 저장할 때 사용하는 로직
    // mysql 에서 put -> insert(), flush -> commit()

    @Override
    public void stop() {}
}
```




## 카프카 미러메이커

```properties
clusters = A, B

A.bootstrap.servers = A_host1:9092, A_host2:9092, A_host3:9092
B.bootstrap.servers = B_host1:9092, B_host2:9092, B_host3:9092


A->B.enabled = true


A->B.topics = .*

B->A.enabled = true
B->A.topics = .*

# Setting replication factor of newly created remote topics
replication.factor=1

checkpoints.topic.replication.factor=1
heartbeats.topic.replication.factor=1
offset-syncs.topic.replication.factor=1
offset.storage.replication.factor=1
status.storage.replication.factor=1
config.storage.replication.factor=1

```


