---
layout: post
title: Kafka - 2!
subtitle: kafka 책 읽기
categories: kafka
tags: [kafka]
---

## 카프카 브로커

- __카프카 브로커__ : 데이터를 주고받기 위해 사용하는 주체, 데이터를 분산 저장하여 장애 대응 애플리케이션
- 안전한 데이터 보관 및 처리를 위해 3대 이상의 브로커를 1개의 클러스터로 운영 권장
- 클러스터는 프로듀서에서 전송된 데이터를 안전하게 `분산, 복제`를 수행

![image](https://user-images.githubusercontent.com/62547169/165308507-aa71eb46-d31b-4e66-b445-094185921ab8.png)


### 데이터 저장, 전송

![image](https://user-images.githubusercontent.com/62547169/165309960-256d5658-85b3-483d-b9df-fcf2522c1bd5.png)

- server.properties : log.dirs : /data
- 브로커는 프로듀서로부터 전달받은 데이터를 토픽의 파티션에 데이터를 저장
- 토픽의 갯수 = 디렉토리의 갯수

#### 페이지 캐시

```
카프카는 메모리, 데이터베이스에 데이터를 저장하지 않는다. - 파일 시스템 이용
지속적인 입출력이 발생할 때, 파일 시스템은 처리 속도가 늦어지는 현상 발생
카프카에서는 페이지 캐시를 이용하여서 디스크 입출력 속도를 높여 문제를 해결
```
- 메인 메모리의 남는 공간을 활용해 페이지 캐시라는 메모리 공간을 마련
- 파일 I/O의 성능을 향상시키기 위해 사용되는 것
- 사용된 파일의 내용을 저장해 놓았다가 읽을 때 page cache를 활용하여 효율 증가


### 데이터 복제, 싱크

![image](https://user-images.githubusercontent.com/62547169/165312760-ac14a4c4-18d4-4f5f-941d-d7242466307e.png)


- 데이터 복제 : 장애 허용 시스템으로 동작하도록 하는 원동력 -> 장애, 데이터 유실 대응
- 토픽 생성시 복제의 개수 설정 가능 (옵션 미선택 시 브로커 설정 옵션)
- `복제의 개수 증가 -> 저장 용량 증가 -> 데이터를 안전하게 사용 가능`
- `복제의 개수 감소 -> 저장 용량 감소 -> 데이터를 불안전하게 사용 가능`

![image](https://user-images.githubusercontent.com/62547169/165314729-2af30c8c-4540-494e-8b6a-b9c06ccac8eb.png)

- 장애 발생시 해당 브로커의 리더 파티션은 사용 불가능
- 새로운 리더를 선출


### 컨트롤러

- 브로커 중 한대가 컨트롤러 역할
- 다른 브로커들의 상태 체크, 리더파티션 재분배
- 컨트롤러 브로커 장애시 다른 브로커 컨트롤러 역할


### 데이터 삭제

- 오직 브로커만이 데이터를 삭제 가능
- 로그 세그먼트 단위로 삭제 - 다수의 데이터가 존재하여 일반 DB처럼 데이터를 선별해서 삭제 __불가능__
- `log.segement.bytes`, `log.segement.ms` 옵션 값에 따라 세그먼트 파일이 `닫힘` - 기본값 : 1GB
- `log.retention.bytes`, `log.retention.ms` 옵션에 설정 값이 넘으면 `삭제`
- `log.retention.check.interval.ms` 닫힌 세그먼트 `파일 체크 간격`

### 코디네이터

- 컨트롤러와 마찬가지로 브로커 중 한대가 역할
- 컨슈머 그룹의 상태 체크, 파티션을 컨슈머와 매칭 분배
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당
  -파티션을 컨슈머로 재할당하는 과정 - `리밸런스`
  
## 카프카 주키퍼

- 카프카의 메타데이터를 관리하는데 사용
- ./zkCli.sh 명령어로 실행

```bash
[zk: localhost:2181(CONNECTED) 1] ls /
[admin, brokers, cluster, config, consumers, controller, controller_epoch, feature, isr_change_notification, latest_producer_id_block, log_dir_event_notification, zookeeper]
[zk: localhost:2181(CONNECTED) 3] get /brokers/ids/1 
{"features":{},"listener_security_protocol_map":{"PLAINTEXT":"PLAINTEXT"},"endpoints":["PLAINTEXT://172.17.19.25:19092"],"jmx_port":-1,"port":19092,"host":"172.17.19.25","version":5,"timestamp":"1650935071371"}
[zk: localhost:2181(CONNECTED) 4] get /controller
{"version":1,"brokerid":1,"timestamp":"1650935071544"}
[zk: localhost:2181(CONNECTED) 5] ls /brokers/topics
[__consumer_offsets, a_Topic1]
[zk: localhost:2181(CONNECTED) 6] 

```

## 토픽, 파티션

### 토픽
- 데이터를 구분하기 위해 사용하는 `단위`
- 1개 이상의 파티션을 소유
- 프로듀서가 보낸 데이터들 저장 - `레코드`


### 파티션

- 카프카에서 병렬처리의 핵심 - 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리 가능
- 큐와 비슷한 구조

https://needjarvis.tistory.com/603

## 레코드

- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋 헤더로 구성
- 적재된 레코드는 수정 불가능 - 리텐션 기간, 용량 설정에 따라 삭제
- 타임 스탬프 : 레코드가 생성된 시점의 유닉스 타임
- 메시지 키 : 메시지 값 순차처리, 종류 표현
- 메시지 값 : 실질적으로 처리할 데이터 존재
  - 메시지 값은 `직렬화` 되어 브로커에 전송
  - 컨슈머가 이용할 때는 `역직렬화`를 수행 해야함
- 오프셋 : 0 이상의 숫자로 형성
- 헤더 : 레코드의 추가적인 정보를 담는 메타이터 저장소 용도



![image](https://user-images.githubusercontent.com/62547169/165320924-8eb72d2a-54d5-43d6-bcb0-265c1b9a634a.png)





