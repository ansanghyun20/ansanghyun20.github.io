---
layout: post
title: Kafka - 2!
subtitle: kafka 책 읽기
categories: kafka
tags: [kafka]
---

## 카프카 브로커

- __카프카 브로커__ : 데이터를 주고받기 위해 사용하는 주체, 데이터를 분산 저장하여 장애 대응 애플리케이션
- 안전한 데이터 보관 및 처리를 위해 3대 이상의 브로커를 1개의 클러스터로 운영 권장
- 클러스터는 프로듀서에서 전송된 데이터를 안전하게 `분산, 복제`를 수행

![image](https://user-images.githubusercontent.com/62547169/165308507-aa71eb46-d31b-4e66-b445-094185921ab8.png)


### 데이터 저장, 전송

![image](https://user-images.githubusercontent.com/62547169/165309960-256d5658-85b3-483d-b9df-fcf2522c1bd5.png)

- server.properties : log.dirs : /data
- 브로커는 프로듀서로부터 전달받은 데이터를 토픽의 파티션에 데이터를 저장
- 토픽의 갯수 = 디렉토리의 갯수

#### 페이지 캐시

```
카프카는 메모리, 데이터베이스에 데이터를 저장하지 않는다. - 파일 시스템 이용
지속적인 입출력이 발생할 때, 파일 시스템은 처리 속도가 늦어지는 현상 발생
카프카에서는 페이지 캐시를 이용하여서 디스크 입출력 속도를 높여 문제를 해결
```
- 메인 메모리의 남는 공간을 활용해 페이지 캐시라는 메모리 공간을 마련
- 파일 I/O의 성능을 향상시키기 위해 사용되는 것
- 사용된 파일의 내용을 저장해 놓았다가 읽을 때 page cache를 활용하여 효율 증가


### 데이터 복제, 싱크

![image](https://user-images.githubusercontent.com/62547169/165312760-ac14a4c4-18d4-4f5f-941d-d7242466307e.png)


- 데이터 복제 : 장애 허용 시스템으로 동작하도록 하는 원동력 -> 장애, 데이터 유실 대응
- 토픽 생성시 복제의 개수 설정 가능 (옵션 미선택 시 브로커 설정 옵션)
- `복제의 개수 증가 -> 저장 용량 증가 -> 데이터를 안전하게 사용 가능`
- `복제의 개수 감소 -> 저장 용량 감소 -> 데이터를 불안전하게 사용 가능`

![image](https://user-images.githubusercontent.com/62547169/165314729-2af30c8c-4540-494e-8b6a-b9c06ccac8eb.png)

- 장애 발생시 해당 브로커의 리더 파티션은 사용 불가능
- 새로운 리더를 선출


### 컨트롤러

- 브로커 중 한대가 컨트롤러 역할
- 다른 브로커들의 상태 체크, 리더파티션 재분배
- 컨트롤러 브로커 장애시 다른 브로커 컨트롤러 역할


### 데이터 삭제

- 오직 브로커만이 데이터를 삭제 가능
- 로그 세그먼트 단위로 삭제 - 다수의 데이터가 존재하여 일반 DB처럼 데이터를 선별해서 삭제 __불가능__
- `log.segement.bytes`, `log.segement.ms` 옵션 값에 따라 세그먼트 파일이 `닫힘` - 기본값 : 1GB
- `log.retention.bytes`, `log.retention.ms` 옵션에 설정 값이 넘으면 `삭제`
- `log.retention.check.interval.ms` 닫힌 세그먼트 `파일 체크 간격`

### 코디네이터

- 컨트롤러와 마찬가지로 브로커 중 한대가 역할
- 컨슈머 그룹의 상태 체크, 파티션을 컨슈머와 매칭 분배
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당
  -파티션을 컨슈머로 재할당하는 과정 - `리밸런스`
  
## 카프카 주키퍼

- 카프카의 메타데이터를 관리하는데 사용
- ./zkCli.sh 명령어로 실행

```bash
[zk: localhost:2181(CONNECTED) 1] ls /
[admin, brokers, cluster, config, consumers, controller, controller_epoch, feature, isr_change_notification, latest_producer_id_block, log_dir_event_notification, zookeeper]
[zk: localhost:2181(CONNECTED) 3] get /brokers/ids/1 
{"features":{},"listener_security_protocol_map":{"PLAINTEXT":"PLAINTEXT"},"endpoints":["PLAINTEXT://172.17.19.25:19092"],"jmx_port":-1,"port":19092,"host":"172.17.19.25","version":5,"timestamp":"1650935071371"}
[zk: localhost:2181(CONNECTED) 4] get /controller
{"version":1,"brokerid":1,"timestamp":"1650935071544"}
[zk: localhost:2181(CONNECTED) 5] ls /brokers/topics
[__consumer_offsets, a_Topic1]
[zk: localhost:2181(CONNECTED) 6] 

```

## 토픽, 파티션

### 토픽
- 데이터를 구분하기 위해 사용하는 `단위`
- 1개 이상의 파티션을 소유
- 프로듀서가 보낸 데이터들 저장 - `레코드`


### 파티션

- 카프카에서 병렬처리의 핵심 - 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리 가능
- 큐와 비슷한 구조

https://needjarvis.tistory.com/603

## 레코드

- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋 헤더로 구성
- 적재된 레코드는 수정 불가능 - 리텐션 기간, 용량 설정에 따라 삭제
- 타임 스탬프 : 레코드가 생성된 시점의 유닉스 타임
- 메시지 키 : 메시지 값 순차처리, 종류 표현
- 메시지 값 : 실질적으로 처리할 데이터 존재
  - 메시지 값은 `직렬화` 되어 브로커에 전송
  - 컨슈머가 이용할 때는 `역직렬화`를 수행 해야함
- 오프셋 : 0 이상의 숫자로 형성
- 헤더 : 레코드의 추가적인 정보를 담는 메타이터 저장소 용도



![image](https://user-images.githubusercontent.com/62547169/165320924-8eb72d2a-54d5-43d6-bcb0-265c1b9a634a.png)


## 카프카 클라이언트

- 카프카 클러스터에 명령을 내리거나 데이터를 송수신하기 위해 카프카 클라이언트 라이브러리 사용

### 프로듀서 API

- 데이터 전송시 리터 파티션을 가지고 있는 브로커와 직접 통신
- 데이터를 직렬화 하여 브로커에 전송
  - 직렬화 : 자바 또는 외부 시스템에서 사용 가능하도록 바이트 형태로 데이터를 변환하는 기술

dependencies

```gradle

dependencies {
...
implementation 'org.apache.kafka:kafka-clients:3.1.0'
...
}

```

producer.java

```java
package com.example.demo;

import java.util.Properties;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class SimpleKafkaProducer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleKafkaProducer.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVER = "172.17.19.25:9092";

    public static void main(String[] args){
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);    

        String messageValue = "testMessage";
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);

        producer.send(record);

        logger.info("{}", record);
        producer.flush();
        producer.close();

    }

}
```

![image](https://user-images.githubusercontent.com/62547169/165334375-ce82ccd2-d87d-4ff0-9eb9-16680220f6ce.png)

![image](https://user-images.githubusercontent.com/62547169/165334526-adfd6fbe-2fb7-45b8-8ed4-143a5143d01d.png)



토픽 생성

```
./kafka-topics.sh --bootstrap-server 172.17.19.25:19092 --create --topic test --partitions 3
```

카프카 클라이언트 프로듀서 실행

```
acks = -1
batch.size = 16384
bootstrap.servers = [172.17.19.25:19092]
buffer.memory = 33554432
client.dns.lookup = use_all_dns_ips
client.id = producer-1
compression.type = none
connections.max.idle.ms = 540000
delivery.timeout.ms = 120000
enable.idempotence = true
interceptor.classes = []
key.serializer = class org.apache.kafka.common.serialization.StringSerializer
...

2022-04-26 10:53:03.345  INFO 46112 --- [           main] com.example.demo.SimpleKafkaProducer     : ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value=testMessage, timestamp=null)

```

컨슈머 테스트

```
./kafka-console-consumer.sh --bootstrap-server 172.17.19.25:19092 --topic test --from-beginning
testMessage
```

### 프로듀서 중요 개념

<img width="734" alt="image" src="https://user-images.githubusercontent.com/62547169/165332180-079313d1-bfee-4377-99e7-54dc318e1ffd.png">

1. send 호출시 ProducerRecord 파티셔너에서 토픽의 어느 파티션으로 전송될 것인지 결정
2. 파티셔너를 따로 설정하지 않으면 defaultPartitioner로 설정
3. 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 어큐물레이터에 데이터를 버퍼로 쌓아놓고 발송
4. 배치로 묶어 전송함으로써 카프카의 프로듀서 처리량 향상

https://dol9.tistory.com/277

### 프로듀서 옵션

### 필수 옵션

- bootstrap.server
- key.serializer
- value.serializer

### 선택 옵션

- acks
  - 1 : 리더 파티션에 데이터 저장 Default
  - 0 : 프로듀서가 전송한 즉시
  - -1 : min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공
- buffer.memory : 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리양
- retries : 에러를 받고 난 뒤 재전송을 시도하는 횟수
- batch.size : 배치로 전송할 레코드의 최대 용량
- linger.ms : 배치를 전송하기 전까지 기다리는 최소시간
- partitioner.class : 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스
- transactional.id : 프로듀서가 레코드를 전홍할 때 레코드를 트랜잭션 단위로 묶을지 여부


### 컨슈머 API

- 프로듀서에 의해 적재된 데이터를 사용하기 위해 데이터를 가져와서 필요한 처리
- 마케팅 문자를 고객에게 보내는 기능이 있다면 컨슈머는 토픽으로부터 고객 데이터를 가져와서 문자 발송 처리

```java
package com.example.demo;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class SimpleConsumer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleConsumer.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVER = "172.17.19.25:19092";
    private final static String GROUP_ID = "test-group";

    public void consumer(){
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);    
        consumer.subscribe(Arrays.asList(TOPIC_NAME)); // 컨슈머 토픽 할당

        while(true){
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records){
                logger.info("{}", record);

            }
        }
    }
}
```

프로듀서 메시지 전송
```
./kafka-console-producer.sh --bootstrap-server 172.17.19.25:19092 -topic test 
>hello
>test
>sanghyun
```

카프카 클라이언트 컨슈머에서 전송된 메시지 확인
```bash
2022-04-26 11:32:23.022  INFO 58839 --- [           main] com.example.demo.SimpleConsumer          : ConsumerRecord(topic = test, partition = 0, leaderEpoch = 0, offset = 1, CreateTime = 1650987141761, serialized key size = -1, serialized value size = 5, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello)
2022-04-26 11:32:27.411  INFO 58839 --- [           main] com.example.demo.SimpleConsumer          : ConsumerRecord(topic = test, partition = 0, leaderEpoch = 0, offset = 2, CreateTime = 1650987146182, serialized key size = -1, serialized value size = 4, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = test)
2022-04-26 11:32:32.321  INFO 58839 --- [           main] com.example.demo.SimpleConsumer          : ConsumerRecord(topic = test, partition = 0, leaderEpoch = 0, offset = 3, CreateTime = 1650987151005, serialized key size = -1, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = sanghyun)
```
